{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2672b6ff-f2c4-4743-8fc7-58edafc6dcd8",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook is an attempt to perform a literature validation of the top k scoring pathways using Natural Language Processing (NLP) with BioBERT. This is done to proof that the DRW based scoring algorithms provide more biologically correct results than the EG scoring method.\n",
    "\n",
    "It is still to be decided if this will be used in the BOO report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0576f758-26c5-4f92-b203-4ee4b7fd3857",
   "metadata": {},
   "source": [
    "## Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ff9cee2-3b73-4055-bcc2-c33c90dd9f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from Bio import Entrez\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64ef3f31-e322-463a-a92f-819cab0e9ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "363ab06aa1bf4ac7826886c67e0c5f69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/313 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\semde\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\semde\\.cache\\huggingface\\hub\\models--dmis-lab--biobert-base-cased-v1.1. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac283d0a6f00441dab07d777ab280d1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9b78d32eaaf4e11b9968189722110ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")\n",
    "model = AutoModel.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc54398-0b3e-4264-98bd-6b4a1660d283",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49978561-2da5-4977-9fe1-f8a2305b627d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text):\n",
    "    \"\"\"This function ...\"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    embedding = outputs.last_hidden_state.mean(dim=1)\n",
    "    return embedding.squeeze().numpy()\n",
    "\n",
    "def compute_similarity(term, abstract):\n",
    "    \"\"\"This function ...\"\"\"\n",
    "    term_emb = get_embedding(term)\n",
    "    abs_emb = get_embedding(abstract)\n",
    "    return cosine_similarity([term_emb], [abs_emb])[0][0]\n",
    "\n",
    "def fetch_abstracts(query, retmax=50):\n",
    "    \"\"\"This function ...\"\"\"\n",
    "    handle = Entrez.esearch(db=\"pubmed\", term=query, retmax=retmax)\n",
    "    record = Entrez.read(handle)\n",
    "    ids = record[\"IdList\"]\n",
    "    handle = Entrez.efetch(db=\"pubmed\", id=ids, rettype=\"abstract\", retmode=\"text\")\n",
    "    return handle.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fb88b6-7ad3-48e5-a99f-deda80cb4938",
   "metadata": {},
   "source": [
    "# RPTEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1647b38b-99aa-44a5-8971-07486d024467",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"C:/Users/semde/Documents/BOO_Scripts/Data/RPTEC_TXG-MAPr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a137cab-26ba-4d01-9de9-e629120f214c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eg_RPTEC = pd.read_csv(os.path.join(data_dir, \"eg_joined_RPTEC.csv\"))\n",
    "df_drw_RPTEC = pd.read_csv(os.path.join(data_dir, \"drw_joined_RPTEC.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca89ece-71db-4c0a-a140-c8349d5e0ab8",
   "metadata": {},
   "source": [
    "## Eigengene scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2c0b6f-62f4-4b9f-b853-2ecd4137a04c",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b94ed53a-9b82-4711-8952-9c24574b598d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eg_RPTEC = df_eg_RPTEC[[\"sample_id\", \"abs_eg_score\", \"module_number\", \"annotation\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fcec82c-f525-4aa6-a093-b1af082ae0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          sample_id  abs_eg_score  \\\n",
      "2487   LU_HRPTECTERT1_SINGLE_ARISTOLOCHICACID_T3_C2      9.060121   \n",
      "53575       LU_HRPTECTERT1_SINGLE_LEADACETATE_T3_C3      8.701595   \n",
      "2547   LU_HRPTECTERT1_SINGLE_ARISTOLOCHICACID_T2_C3      8.459835   \n",
      "515         LU_HRPTECTERT1_SINGLE_OCHRATOXINA_T2_C2      7.878635   \n",
      "525         LU_HRPTECTERT1_SINGLE_OCHRATOXINA_T2_C3      7.812291   \n",
      "\n",
      "       module_number                                         annotation  \n",
      "2487              11  immune(immune, natural killer cell, lymphocyte...  \n",
      "53575            264  metabolism(metabolism), rna processing(transcr...  \n",
      "2547              11  immune(immune, natural killer cell, lymphocyte...  \n",
      "515                3  metabolism(metabolism), mitochondria(mitochond...  \n",
      "525                3  metabolism(metabolism), mitochondria(mitochond...  \n"
     ]
    }
   ],
   "source": [
    "df_eg_RPTEC = df_eg_RPTEC.sort_values(by=\"abs_eg_score\", ascending=False)\n",
    "print(df_eg_RPTEC.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f886a3f-c38d-4309-9a17-e0a61670e535",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "150553e9-1b8d-4f16-acbf-f522c56c2672",
   "metadata": {},
   "source": [
    "## Weighted Directed Random Walk (wDRW)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0afde8e-b9e1-4357-9c1e-ac352168dab8",
   "metadata": {},
   "source": [
    "## Weighted Significant Directed Random Walk (s-wDRW)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f7a523-9bdd-4a98-9419-daea5e57be16",
   "metadata": {},
   "source": [
    "# PHH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4db784-7715-4fd4-b079-8992870faf71",
   "metadata": {},
   "source": [
    "## Eigengene scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e2e1dc-3942-40cc-8e6c-5e38666f0f69",
   "metadata": {},
   "source": [
    "## Weighted Directed Random Walk (wDRW)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adaaa75-cecd-45f2-9d3c-3234fe40ec02",
   "metadata": {},
   "source": [
    "## Weighted Significant Directed Random Walk (s-wDRW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476feaf9-6dd4-46d0-ab5a-da6773f11dad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
